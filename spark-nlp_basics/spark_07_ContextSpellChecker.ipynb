{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spark_07_ContextSpellChecker.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM/aC811biGGsow1CLMqhTL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/onlyabhilash/Spark_NLP/blob/main/spark-nlp_basics/spark_07_ContextSpellChecker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "RtCxN_2Rt8aB",
        "outputId": "b064152d-9442-43bc-8cff-0a16c3a3ea72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openjdk version \"1.8.0_312\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_312-8u312-b07-0ubuntu1~18.04-b07)\n",
            "OpenJDK 64-Bit Server VM (build 25.312-b07, mixed mode)\n",
            "\u001b[K     |████████████████████████████████| 215.7 MB 58 kB/s \n",
            "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /simple/py4j/\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 197 kB 51.2 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 138 kB 26.2 MB/s \n",
            "\u001b[?25hSpark NLP version 2.7.1\n",
            "Apache Spark version: 2.4.4\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fea84577d50>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://cac1357331b6:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v2.4.4</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark NLP</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Install java\n",
        "! apt-get update -qq\n",
        "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "! java -version\n",
        "\n",
        "# Install pyspark\n",
        "! pip install --ignore-installed -q pyspark==2.4.4\n",
        "! pip install --ignore-installed -q spark-nlp==2.7.1\n",
        "\n",
        "import sparknlp\n",
        "\n",
        "spark = sparknlp.start() # for GPU training >> sparknlp.start(gpu = True) # for Spark 2.3 =>> sparknlp.start(spark23 = True)\n",
        "\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "from pyspark.ml import Pipeline\n",
        "import pandas as pd\n",
        "\n",
        "print(\"Spark NLP version\", sparknlp.version())\n",
        "\n",
        "print(\"Apache Spark version:\", spark.version)\n",
        "\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sparknlp.common import *\n",
        "from IPython.utils.text import columnize"
      ],
      "metadata": {
        "id": "ldTvx_TXuD90"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documentAssembler = DocumentAssembler()\\\n",
        "  .setInputCol(\"text\")\\\n",
        "  .setOutputCol(\"document\")\n",
        "\n",
        "tokenizer = RecursiveTokenizer()\\\n",
        "  .setInputCols([\"document\"])\\\n",
        "  .setOutputCol(\"token\")\\\n",
        "  .setPrefixes([\"\\\"\", \"(\", \"[\", \"\\n\"])\\\n",
        "  .setSuffixes([\".\", \",\", \"?\", \")\",\"!\", \"'s\"])\n",
        "\n",
        "spellModel = ContextSpellCheckerModel\\\n",
        "    .pretrained('spellcheck_dl')\\\n",
        "    .setInputCols(\"token\")\\\n",
        "    .setOutputCol(\"checked\")\\\n",
        "    .setErrorThreshold(4.0)\\\n",
        "    .setTradeoff(6.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74pAz5WZxX35",
        "outputId": "7ee6af37-3267-4a23-e38b-82f13654b216"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spellcheck_dl download started this may take some time.\n",
            "Approximate size to download 112 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finisher = Finisher()\\\n",
        "    .setInputCols(\"checked\")\n",
        "\n",
        "pipeline = Pipeline(\n",
        "    stages = [\n",
        "    documentAssembler,\n",
        "    tokenizer,\n",
        "    spellModel,\n",
        "    finisher\n",
        "  ])\n",
        "\n",
        "empty_ds = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
        "lp = LightPipeline(pipeline.fit(empty_ds))"
      ],
      "metadata": {
        "id": "DjQ7hoDJ6Iyd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lp.annotate(\"Plaese alliow me tao introdduce myhelf, I am a man of waelth und tiaste\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rD6ywjo39Lsq",
        "outputId": "033cbfd1-fd72-4c69-f8aa-e5b72b776feb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'checked': ['Please',\n",
              "  'allow',\n",
              "  'me',\n",
              "  'to',\n",
              "  'introduce',\n",
              "  'myself',\n",
              "  ',',\n",
              "  'I',\n",
              "  'am',\n",
              "  'a',\n",
              "  'man',\n",
              "  'of',\n",
              "  'wealth',\n",
              "  'and',\n",
              "  'taste']}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Word Level Corrections"
      ],
      "metadata": {
        "id": "x4OXF_BHCWin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First let's start with a loaded model, and check which classes it has been trained with\n",
        "spellModel.getWordClasses()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7LJz05ZCZsC",
        "outputId": "6318d8c1-bd7f-427c-de11-57bf52442a56"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['(_AGE_,RegexParser)',\n",
              " '(_NUM_,RegexParser)',\n",
              " '(_LOC_,VocabParser)',\n",
              " '(_DATE_,RegexParser)',\n",
              " '(_NAME_,VocabParser)']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "beautify = lambda annotations: [columnize(sent['checked']) for sent in annotations]"
      ],
      "metadata": {
        "id": "v2UYxV3EPlXZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Foreign name without errors\n",
        "sample = 'We are going to meet Jowita in the city hall.'\n",
        "beautify([lp.annotate(sample)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7IuCtYMwxem",
        "outputId": "8cd4a2f6-170c-4a51-cccc-efba84f4e99e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['We  are  going  to  meet  Moita  in  the  city  hall  .\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Well, the result is not very good, that's because the Spell Checker has been trained mainly with American English texts. At least, the surrounding words are helping to obtain a correction that is a name. We can do better, let's see how."
      ],
      "metadata": {
        "id": "ImTEekpfxl1j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Updating a predefined word class\n",
        "### Vocabulary Classes\n",
        "In order for the Spell Checker to be able to preserve words, like a foreign name, we have the option to update existing classes so they can cover new words."
      ],
      "metadata": {
        "id": "PLl9Atxfxspo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# add some more, in case we need them\n",
        "spellModel.updateVocabClass('_NAME_', ['Monika', 'Agnieszka', 'Inga', 'Jowita', 'Melania'], True)\n",
        "\n",
        "# Let's see what we get now\n",
        "sample = 'We are going to meet Jowita at the city hall.'\n",
        "beautify([lp.annotate(sample)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NI6MiUqOxwQ3",
        "outputId": "1bcdea08-8c1a-47c9-aeaa-4b81251d5b4d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['We  are  going  to  meet  Jowita  at  the  city  hall  .\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Much better, right? Now suppose that we want to be able to not only preserve the word, but also to propose meaningful corrections to the name of our foreign friend."
      ],
      "metadata": {
        "id": "tWVkj68-zcuF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Foreign name with an error\n",
        "sample = 'We are going to meet Jovita in the city hall.'\n",
        "beautify([lp.annotate(sample)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNjNhGplzdlB",
        "outputId": "33255685-ed22-4bd5-a647-8a638765d790"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['We  are  going  to  meet  Jowita  in  the  city  hall  .\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we were able to add the new word to the class and propose corrections for it, but also, the new word has been treated as a name, that meaning that the model used information about the typical context for names in order to produce the best correction."
      ],
      "metadata": {
        "id": "IvipjvV6zrYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VFgl5Uh1ztD3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regex Classes\n",
        "We can do something similar for classes defined by regex. We can add a regex, to for example deal with a special format for dates, that will not only preserve the date with the special format, but also be able to correct it."
      ],
      "metadata": {
        "id": "IiZ_0HBJ0Wad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Date with custom format\n",
        "sample = 'We are going to meet her in the city hall on february-3.'\n",
        "beautify([lp.annotate(sample)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnoJJ-l70XJU",
        "outputId": "1dc61e6b-a0b7-4df6-e678-9648f3740411"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['We  are  going  to  meet  her  in  the  city  all  on  February  .\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this is a sample regex, for simplicity not covering all months\n",
        "spellModel.updateRegexClass('_DATE_', '(january|february|march)-[0-31]')\n",
        "beautify([lp.annotate(sample)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxzyCM8O5Hd_",
        "outputId": "2f1964ce-7f43-4b2f-e651-f1b97f4c70b7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['We  are  going  to  meet  her  in  the  city  all  on  february-3  .\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now check that it produces good corrections to the date\n",
        "sample = 'We are going to meet her in the city hall on febbruary-3.'\n",
        "beautify([lp.annotate(sample)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaWgemyGqkac",
        "outputId": "0190e41d-4995-4c85-ee51-a00c39139c73"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['We  are  going  to  meet  her  in  the  city  all  on  february-3  .\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And the model produces good corrections for the special regex class. Remember that each regex that you enter to the model must be finite. In all these examples the new definitions for our classes didn't prevent the model to continue using the context to produce corrections. Let's see why being able to use the context is important."
      ],
      "metadata": {
        "id": "5cG1CyxftqGN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sentence Level Corrections\n",
        "The Spell Checker can leverage the context of words for ranking different correction sequences. Let's take a look at some examples,\n",
        "\n"
      ],
      "metadata": {
        "id": "UIlIIxjN9zPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check for the different occurrences of the word \"siter\"\n",
        "example1 = [\"I will call my siter.\",\\\n",
        "    \"Due to bad weather, we had to move to a different siter.\",\\\n",
        "    \"We travelled to three siter in the summer.\"]\n",
        "beautify(lp.annotate(example1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAfxpA5VtTXS",
        "outputId": "9de46fa0-03c6-414c-b727-0273a0c32093"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I  will  call  my  sister  .\\n',\n",
              " 'Due  to  bad  weather  ,  we  had  to  move  to  a  different  site  .\\n',\n",
              " 'We  travelled  to  three  sites  in  the  summer  .\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check for the different occurrences of the word \"ueather\"\n",
        "example2 = [\"During the summer we have the best ueather.\",\\\n",
        "    \"I have a black ueather jacket, so nice.\",\\\n",
        "    \"I introduce you to my sister, she is called ueather.\"]\n",
        "beautify(lp.annotate(example2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBeygNcc_k2l",
        "outputId": "3b3d313f-b07d-44f6-be34-ac670e9a5ebb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['During  the  summer  we  have  the  best  Heather  .\\n',\n",
              " 'I  have  a  black  leather  jacket  ,  so  nice  .\\n',\n",
              " 'I  introduce  you  to  my  sister  ,  she  is  called  Heather  .\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Subword level corrections"
      ],
      "metadata": {
        "id": "wq4CgL46aYmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sending or lending ?\n",
        "sample = 'I will be 1ending him my car'\n",
        "lp.annotate(sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZIGioRQAw_K",
        "outputId": "bb5db65e-2b8d-4ac5-9f35-3058d7f44c12"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'checked': ['I', 'will', 'be', 'sending', 'him', 'my', 'car']}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's make the replacement of an '1' for an 'l' cheaper\n",
        "weights = {'1': {'l': .1}}\n",
        "spellModel.setWeights(weights)\n",
        "lp.annotate(sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMlMcoL9B492",
        "outputId": "d01c759e-74a9-44c8-af9d-b442afa60cab"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'checked': ['I', 'will', 'be', 'lending', 'him', 'my', 'car']}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Advanced - the mysterious tradeoff parameter"
      ],
      "metadata": {
        "id": "rJRbDVMEdFlF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample = 'have you been two the falls?'\n",
        "beautify([lp.annotate(sample)])"
      ],
      "metadata": {
        "id": "Jbv70nBeJ8R4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3750bae4-b70e-4c27-8033-8c77f7b4a101"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['have  you  been  two  the  falls  ?\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spellModel.getTradeoff()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eveVKqU9dJEE",
        "outputId": "be84a706-1775-4701-a8ab-c92f49a86284"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.0"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's decrease the influence of word-level errors\n",
        "# TODO a nicer way of doing this other than re-creating the pipeline?\n",
        "spellModel.setTradeoff(5.0)\n",
        "\n",
        "pipeline = Pipeline(\n",
        "    stages = [\n",
        "    documentAssembler,\n",
        "    tokenizer,\n",
        "    spellModel,\n",
        "    finisher\n",
        "  ])\n",
        "\n",
        "empty_ds = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
        "lp = LightPipeline(pipeline.fit(empty_ds))\n",
        "\n",
        "beautify([lp.annotate(sample)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZxgZgQ2dL5y",
        "outputId": "0dbe5e4d-5ced-4974-bb36-5d9f84e22008"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['have  you  been  to  the  falls  ?\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Advanced - performance"
      ],
      "metadata": {
        "id": "CKZqApv0eG0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sparknlp_spell_check(text):\n",
        "\n",
        "  return beautify([lp.annotate(text)])[0].rstrip()"
      ],
      "metadata": {
        "id": "LWaFldQmeFx7"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sparknlp_spell_check('I will go to Philadelhia tomorrow')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7QQL8VkfeBcg",
        "outputId": "4cf1d4e3-16fd-4480-83c4-2961bd4c7629"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I  will  go  to  Philadelphia  tomorrow'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sparknlp_spell_check('I will go to Philadhelpia tomorrow')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GVzsUOSuEWsc",
        "outputId": "7e83d3a7-cfa7-4bd5-a170-35a004376451"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I  will  go  to  Philadelphia  tomorrow'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sparknlp_spell_check('I will go to Piladelphia tomorrow')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7UC7uNWkFM__",
        "outputId": "9d3722e0-3366-48b6-8e67-980d1ea4acbf"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I  will  go  to  Philadelphia  tomorrow'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sparknlp_spell_check('I will go to Philadedlphia tomorrow')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3L1KR4e1FUoA",
        "outputId": "ec78069a-1f2b-459d-cab6-b97be59e1d14"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I  will  go  to  Philadelphia  tomorrow'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sparknlp_spell_check('I will go to Phieladelphia tomorrow')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "d_RB47ssFYlu",
        "outputId": "410f942e-cd24-43d9-8f54-46bd21ee54f7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I  will  go  to  Philadelphia  tomorrow'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Pt8OeeygF8p1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}