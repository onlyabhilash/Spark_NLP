{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/onlyabhilash/Spark_NLP/blob/main/spark-nlp_basics/spark_05_Text_classification_examples_in_SparkML_SparkNLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "034_KMGM9mc_"
      },
      "source": [
        "# Text Classification with Spark NLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kjPbxOgXJCp",
        "outputId": "aefc3367-3bad-48b9-9720-4373b741a8a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openjdk version \"1.8.0_312\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_312-8u312-b07-0ubuntu1~18.04-b07)\n",
            "OpenJDK 64-Bit Server VM (build 25.312-b07, mixed mode)\n",
            "\u001b[K     |████████████████████████████████| 215.7 MB 59 kB/s \n",
            "\u001b[K     |████████████████████████████████| 197 kB 20.5 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 124 kB 9.0 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Install java\n",
        "! apt-get update -qq\n",
        "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "! java -version\n",
        "\n",
        "# Install pyspark\n",
        "! pip install --ignore-installed -q pyspark==2.4.4\n",
        "! pip install --ignore-installed -q spark-nlp==2.5.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G39auh1iXJCs"
      },
      "source": [
        "\n",
        "<b>  if you want to work with Spark 2.3 </b>\n",
        "```\n",
        "import os\n",
        "\n",
        "# Install java\n",
        "! apt-get update -qq\n",
        "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-2.3.0/spark-2.3.0-bin-hadoop2.7.tgz\n",
        "\n",
        "!tar xf spark-2.3.0-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.3.0-bin-hadoop2.7\"\n",
        "! java -version\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "! pip install --ignore-installed -q spark-nlp==2.5.5\n",
        "\n",
        "import sparknlp\n",
        "\n",
        "spark = sparknlp.start(spark23=True)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pihatz2EIPPM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.common import *\n",
        "from sparknlp.base import *\n",
        "\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lNrhGDbIPPP",
        "outputId": "436277f0-f2ae-4c8c-8141-4b25664225cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP version:  2.5.5\n",
            "Apache Spark version:  2.4.4\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import sparknlp\n",
        "spark = sparknlp.start()\n",
        "\n",
        "print(\"Spark NLP version: \", sparknlp.version())\n",
        "print(\"Apache Spark version: \", spark.version)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IawvXkLGIPPS",
        "outputId": "7cfbb013-1c86-4e4e-cc28-775b9e00aff8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-18 05:56:48--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/data/news_category_train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 24032125 (23M) [text/plain]\n",
            "Saving to: ‘news_category_train.csv’\n",
            "\n",
            "news_category_train 100%[===================>]  22.92M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2022-03-18 05:56:50 (202 MB/s) - ‘news_category_train.csv’ saved [24032125/24032125]\n",
            "\n",
            "--2022-03-18 05:56:50--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/data/news_category_test.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1504408 (1.4M) [text/plain]\n",
            "Saving to: ‘news_category_test.csv’\n",
            "\n",
            "news_category_test. 100%[===================>]   1.43M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2022-03-18 05:56:51 (32.9 MB/s) - ‘news_category_test.csv’ saved [1504408/1504408]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/data/news_category_train.csv\n",
        "! wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/data/news_category_test.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GkCjlO9IPPh",
        "outputId": "d2d88382-a65c-4e30-b038-9af6d64d1f37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------------------------------------+\n",
            "|category|                                       description|\n",
            "+--------+--------------------------------------------------+\n",
            "|Business| Short sellers, Wall Street's dwindling band of...|\n",
            "|Business| Private investment firm Carlyle Group, which h...|\n",
            "|Business| Soaring crude prices plus worries about the ec...|\n",
            "|Business| Authorities have halted oil export flows from ...|\n",
            "|Business| Tearaway world oil prices, toppling records an...|\n",
            "|Business| Stocks ended slightly higher on Friday but sta...|\n",
            "|Business| Assets of the nation's retail money market mut...|\n",
            "|Business| Retail sales bounced back a bit in July, and n...|\n",
            "|Business|\" After earning a PH.D. in Sociology, Danny Baz...|\n",
            "|Business| Short sellers, Wall Street's dwindling  band o...|\n",
            "|Business| Soaring crude prices plus worries  about the e...|\n",
            "|Business| OPEC can do nothing to douse scorching  oil pr...|\n",
            "|Business| Non OPEC oil exporters should consider  increa...|\n",
            "|Business| WASHINGTON/NEW YORK (Reuters) - The auction fo...|\n",
            "|Business| The dollar tumbled broadly on Friday  after da...|\n",
            "|Business|If you think you may need to help your elderly ...|\n",
            "|Business|The purchasing power of kids is a big part of w...|\n",
            "|Business|There is little cause for celebration in the st...|\n",
            "|Business|The US trade deficit has exploded 19 to a recor...|\n",
            "|Business|Oil giant Shell could be bracing itself for a t...|\n",
            "+--------+--------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# newsDF = spark.read.parquet(\"data/news_category.parquet\") >> if it is a parquet\n",
        "\n",
        "newsDF = spark.read \\\n",
        "      .option(\"header\", True) \\\n",
        "      .csv(\"news_category_train.csv\")\n",
        "\n",
        "newsDF.show(truncate=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rd8rKZEcIPPl",
        "outputId": "b9017790-71e5-4023-f7d0-802df02b4c7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------------------------------------+\n",
            "|category|                                       description|\n",
            "+--------+--------------------------------------------------+\n",
            "|Business| Short sellers, Wall Street's dwindling band of...|\n",
            "|Business| Private investment firm Carlyle Group, which h...|\n",
            "|Business| Soaring crude prices plus worries about the ec...|\n",
            "|Business| Authorities have halted oil export flows from ...|\n",
            "|Business| Tearaway world oil prices, toppling records an...|\n",
            "|Business| Stocks ended slightly higher on Friday but sta...|\n",
            "|Business| Assets of the nation's retail money market mut...|\n",
            "|Business| Retail sales bounced back a bit in July, and n...|\n",
            "|Business|\" After earning a PH.D. in Sociology, Danny Baz...|\n",
            "|Business| Short sellers, Wall Street's dwindling  band o...|\n",
            "|Business| Soaring crude prices plus worries  about the e...|\n",
            "|Business| OPEC can do nothing to douse scorching  oil pr...|\n",
            "|Business| Non OPEC oil exporters should consider  increa...|\n",
            "|Business| WASHINGTON/NEW YORK (Reuters) - The auction fo...|\n",
            "|Business| The dollar tumbled broadly on Friday  after da...|\n",
            "|Business|If you think you may need to help your elderly ...|\n",
            "|Business|The purchasing power of kids is a big part of w...|\n",
            "|Business|There is little cause for celebration in the st...|\n",
            "|Business|The US trade deficit has exploded 19 to a recor...|\n",
            "|Business|Oil giant Shell could be bracing itself for a t...|\n",
            "+--------+--------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "newsDF.show(truncate=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjkkY5FTIPPp",
        "outputId": "585416b5-423e-427d-dec3-457bc3c55c30"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(category='Business', description=\" Short sellers, Wall Street's dwindling band of ultra cynics, are seeing green again.\"),\n",
              " Row(category='Business', description=' Private investment firm Carlyle Group, which has a reputation for making well timed and occasionally controversial plays in the defense industry, has quietly placed its bets on another part of the market.')]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "newsDF.take(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xsifu6-cIPPs",
        "outputId": "20f07c2a-a755-4b97-de15-a683242dbfa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----+\n",
            "|category|count|\n",
            "+--------+-----+\n",
            "|   World|30000|\n",
            "|Sci/Tech|30000|\n",
            "|Business|30000|\n",
            "|  Sports|30000|\n",
            "+--------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "newsDF.groupBy(\"category\") \\\n",
        "    .count() \\\n",
        "    .orderBy(col(\"count\").desc()) \\\n",
        "    .show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHn5crTvIPPv"
      },
      "source": [
        "## Building Classification Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8zK3RByIPPw"
      },
      "source": [
        "### LogReg with CountVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AM7esk5yIPPx"
      },
      "source": [
        "Tokenizer: Tokenization \n",
        "\n",
        "stopwordsRemover: Remove Stop Words\n",
        "\n",
        "countVectors: Count vectors (“document-term vectors”)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbrPTtZpIPPx"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import CountVectorizer, HashingTF, IDF, OneHotEncoder, StringIndexer, VectorAssembler, SQLTransformer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dL-SK95DIPP1",
        "outputId": "9c9ec261-4a09-4948-8bf3-70a97d9525a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 691 ms, sys: 103 ms, total: 794 ms\n",
            "Wall time: 1min 34s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "document_assembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"description\") \\\n",
        "    .setOutputCol(\"document\")\n",
        "    \n",
        "tokenizer = Tokenizer() \\\n",
        "  .setInputCols([\"document\"]) \\\n",
        "  .setOutputCol(\"token\")\n",
        "    \n",
        "normalizer = Normalizer() \\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"normalized\")\n",
        "\n",
        "stopwords_cleaner = StopWordsCleaner()\\\n",
        "      .setInputCols(\"normalized\")\\\n",
        "      .setOutputCol(\"cleanTokens\")\\\n",
        "      .setCaseSensitive(False)\n",
        "\n",
        "stemmer = Stemmer() \\\n",
        "    .setInputCols([\"cleanTokens\"]) \\\n",
        "    .setOutputCol(\"stem\")\n",
        "\n",
        "finisher = Finisher() \\\n",
        "    .setInputCols([\"stem\"]) \\\n",
        "    .setOutputCols([\"token_features\"]) \\\n",
        "    .setOutputAsArray(True) \\\n",
        "    .setCleanAnnotations(False)\n",
        "\n",
        "countVectors = CountVectorizer(inputCol=\"token_features\", outputCol=\"features\", vocabSize=10000, minDF=5)\n",
        "\n",
        "label_stringIdx = StringIndexer(inputCol = \"category\", outputCol = \"label\")\n",
        "\n",
        "nlp_pipeline = Pipeline(\n",
        "    stages=[document_assembler, \n",
        "            tokenizer,\n",
        "            normalizer,\n",
        "            stopwords_cleaner, \n",
        "            stemmer, \n",
        "            finisher,\n",
        "           countVectors,\n",
        "           label_stringIdx])\n",
        "\n",
        "nlp_model = nlp_pipeline.fit(newsDF)\n",
        "\n",
        "processed = nlp_model.transform(newsDF)\n",
        "\n",
        "processed.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEtzQbNwIPP4",
        "outputId": "6857da16-2a78-45a4-868e-749924ff3a8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------+--------------------------------------------------+\n",
            "|                                       description|                                    token_features|\n",
            "+--------------------------------------------------+--------------------------------------------------+\n",
            "| Short sellers, Wall Street's dwindling band of...|[short, seller, wall, street, dwindl, band, ult...|\n",
            "| Private investment firm Carlyle Group, which h...|[privat, invest, firm, carlyl, group, reput, ma...|\n",
            "| Soaring crude prices plus worries about the ec...|[soar, crude, price, plu, worri, economi, outlo...|\n",
            "| Authorities have halted oil export flows from ...|[author, halt, oil, export, flow, main, pipelin...|\n",
            "| Tearaway world oil prices, toppling records an...|[tearawai, world, oil, price, toppl, record, st...|\n",
            "| Stocks ended slightly higher on Friday but sta...|[stock, end, slightli, higher, fridai, staye, n...|\n",
            "| Assets of the nation's retail money market mut...|[asset, nation, retail, monei, market, mutual, ...|\n",
            "| Retail sales bounced back a bit in July, and n...|[retail, sale, bounc, back, bit, juli, new, cla...|\n",
            "|\" After earning a PH.D. in Sociology, Danny Baz...|[earn, phd, sociologi, danni, bazil, rilei, sta...|\n",
            "| Short sellers, Wall Street's dwindling  band o...|[short, seller, wall, street, dwindl, band, ult...|\n",
            "| Soaring crude prices plus worries  about the e...|[soar, crude, price, plu, worri, economi, outlo...|\n",
            "| OPEC can do nothing to douse scorching  oil pr...|[opec, noth, dous, scorch, oil, price, market, ...|\n",
            "| Non OPEC oil exporters should consider  increa...|[non, opec, oil, export, consid, increas, outpu...|\n",
            "| WASHINGTON/NEW YORK (Reuters) - The auction fo...|[washingtonnew, york, reuter, auction, googl, i...|\n",
            "| The dollar tumbled broadly on Friday  after da...|[dollar, tumbl, broadli, fridai, data, showe, r...|\n",
            "|If you think you may need to help your elderly ...|[think, mai, ne, help, elderli, rel, financ, do...|\n",
            "|The purchasing power of kids is a big part of w...|[purchas, power, kid, big, part, backtoschool, ...|\n",
            "|There is little cause for celebration in the st...|[littl, caus, celebr, stock, market, dai, inves...|\n",
            "|The US trade deficit has exploded 19 to a recor...|[u, trade, deficit, explod, record, bn, oil, co...|\n",
            "|Oil giant Shell could be bracing itself for a t...|[oil, giant, shell, brace, takeov, attempt, pos...|\n",
            "+--------------------------------------------------+--------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "processed.select('description','token_features').show(truncate=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mq7tQ_vsIPP7",
        "outputId": "afae2643-8372-4954-9385-eccb9f8e741b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(token_features=['short', 'seller', 'wall', 'street', 'dwindl', 'band', 'ultra', 'cynic', 'see', 'green']),\n",
              " Row(token_features=['privat', 'invest', 'firm', 'carlyl', 'group', 'reput', 'make', 'well', 'time', 'occasion', 'controversi', 'plai', 'defens', 'industri', 'quietli', 'place', 'bet', 'anoth', 'part', 'market'])]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "processed.select('token_features').take(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5R98lqSgIPP_",
        "outputId": "2c664153-2ddb-4ba3-8089-20019b915a37"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(features=SparseVector(10000, {241: 1.0, 384: 1.0, 467: 1.0, 743: 1.0, 837: 1.0, 2233: 1.0, 3690: 1.0, 6224: 1.0, 6295: 1.0})),\n",
              " Row(features=SparseVector(10000, {26: 1.0, 38: 1.0, 46: 1.0, 68: 1.0, 117: 1.0, 155: 1.0, 182: 1.0, 197: 1.0, 245: 1.0, 304: 1.0, 320: 1.0, 407: 1.0, 427: 1.0, 621: 1.0, 867: 1.0, 2362: 1.0, 2834: 1.0, 2861: 1.0, 6877: 1.0}))]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "processed.select('features').take(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfnlWafuIPQC",
        "outputId": "056c2b84-73da-418e-8040-2acb8c7a42f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+-----+\n",
            "|         description|            features|label|\n",
            "+--------------------+--------------------+-----+\n",
            "| Short sellers, W...|(10000,[241,384,4...|  1.0|\n",
            "| Private investme...|(10000,[26,38,46,...|  1.0|\n",
            "| Soaring crude pr...|(10000,[15,28,46,...|  1.0|\n",
            "| Authorities have...|(10000,[0,32,35,4...|  1.0|\n",
            "| Tearaway world o...|(10000,[1,2,11,28...|  1.0|\n",
            "| Stocks ended sli...|(10000,[3,13,14,2...|  1.0|\n",
            "| Assets of the na...|(10000,[0,4,10,15...|  1.0|\n",
            "| Retail sales bou...|(10000,[0,1,10,15...|  1.0|\n",
            "|\" After earning a...|(10000,[98,99,125...|  1.0|\n",
            "| Short sellers, W...|(10000,[241,384,4...|  1.0|\n",
            "| Soaring crude pr...|(10000,[15,28,46,...|  1.0|\n",
            "| OPEC can do noth...|(10000,[0,24,28,2...|  1.0|\n",
            "| Non OPEC oil exp...|(10000,[0,21,28,3...|  1.0|\n",
            "| WASHINGTON/NEW Y...|(10000,[2,4,13,14...|  1.0|\n",
            "| The dollar tumbl...|(10000,[2,14,72,1...|  1.0|\n",
            "|If you think you ...|(10000,[74,77,143...|  1.0|\n",
            "|The purchasing po...|(10000,[46,54,167...|  1.0|\n",
            "|There is little c...|(10000,[29,46,75,...|  1.0|\n",
            "|The US trade defi...|(10000,[2,32,72,1...|  1.0|\n",
            "|Oil giant Shell c...|(10000,[16,32,103...|  1.0|\n",
            "+--------------------+--------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "processed.select('description','features','label').show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQwMyjUdIPQF",
        "outputId": "d02a3fac-2b39-43a2-9a1e-1a09af08a1d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Dataset Count: 84038\n",
            "Test Dataset Count: 35962\n"
          ]
        }
      ],
      "source": [
        "# set seed for reproducibility\n",
        "(trainingData, testData) = processed.randomSplit([0.7, 0.3], seed = 100)\n",
        "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
        "print(\"Test Dataset Count: \" + str(testData.count()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cq30cb17IPQH",
        "outputId": "e62cbcb1-6fbb-44c2-f4a6-075188931a7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- category: string (nullable = true)\n",
            " |-- description: string (nullable = true)\n",
            " |-- document: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- token: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- normalized: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- cleanTokens: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- stem: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- token_features: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- features: vector (nullable = true)\n",
            " |-- label: double (nullable = false)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "trainingData.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1LRyPzWIPQK",
        "outputId": "94d9c465-f7e9-4da3-b46a-e0547c98a57f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------+--------+------------------------------+-----+----------+\n",
            "|                   description|category|                   probability|label|prediction|\n",
            "+------------------------------+--------+------------------------------+-----+----------+\n",
            "|Novell brings updated kerne...|Business|[0.9999995974765189,2.43882...|  1.0|       0.0|\n",
            "| Cray taps Linux for more a...|Sci/Tech|[0.9999892931501291,5.27087...|  0.0|       0.0|\n",
            "|F5 bolsters firewall family...|Sci/Tech|[0.9999765458165976,2.06665...|  0.0|       0.0|\n",
            "| You Software Inc. announce...|Sci/Tech|[0.9999614023465399,1.09613...|  0.0|       0.0|\n",
            "|Awarding the iMac G5 five s...|Sci/Tech|[0.9997506483003618,1.63025...|  0.0|       0.0|\n",
            "|\\\\I've blogged before  abou...|Sci/Tech|[0.999593913378917,3.198068...|  0.0|       0.0|\n",
            "| At a special music event o...|Sci/Tech|[0.9995669801377939,3.20953...|  0.0|       0.0|\n",
            "| Not long ago most corporat...|Sci/Tech|[0.9995532840436969,2.59983...|  0.0|       0.0|\n",
            "|IBM Corp. next week will be...|Sci/Tech|[0.9995336047096918,2.35770...|  0.0|       0.0|\n",
            "|\\\\Sam blogs about his wiki ...|Sci/Tech|[0.9994961857246952,1.47533...|  0.0|       0.0|\n",
            "+------------------------------+--------+------------------------------+-----+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0)\n",
        "\n",
        "lrModel = lr.fit(trainingData)\n",
        "\n",
        "predictions = lrModel.transform(testData)\n",
        "\n",
        "predictions.filter(predictions['prediction'] == 0) \\\n",
        "    .select(\"description\",\"category\",\"probability\",\"label\",\"prediction\") \\\n",
        "    .orderBy(\"probability\", ascending=False) \\\n",
        "    .show(n = 10, truncate = 30)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPRKc6_1IPQO"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
        "\n",
        "#evaluator.evaluate(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rOj1_VXIPQQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "y_true = predictions.select(\"label\")\n",
        "y_true = y_true.toPandas()\n",
        "\n",
        "y_pred = predictions.select(\"prediction\")\n",
        "y_pred = y_pred.toPandas()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEgXvy9KIPQT",
        "outputId": "8595017f-ec4d-4949-c1ec-aa62c8fe59ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.0    9385\n",
              "0.0    9047\n",
              "1.0    8865\n",
              "2.0    8665\n",
              "Name: prediction, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "y_pred.prediction.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AHRzWCZIPQW",
        "outputId": "f3b205c7-a83d-4681-a64b-ff8d01ea4c98"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7791,  730,  311,  118],\n",
              "       [ 882, 7657,  284,   85],\n",
              "       [ 311,  426, 7992,  289],\n",
              "       [  63,   52,   78, 8893]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "cnf_matrix = confusion_matrix(list(y_true.label.astype(int)), list(y_pred.prediction.astype(int)))\n",
        "cnf_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTNup21PIPQZ",
        "outputId": "65bc8b2f-c94b-4a3c-b758-5c1ae8ab8749"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.86      0.87      0.87      8950\n",
            "         1.0       0.86      0.86      0.86      8908\n",
            "         2.0       0.92      0.89      0.90      9018\n",
            "         3.0       0.95      0.98      0.96      9086\n",
            "\n",
            "    accuracy                           0.90     35962\n",
            "   macro avg       0.90      0.90      0.90     35962\n",
            "weighted avg       0.90      0.90      0.90     35962\n",
            "\n",
            "0.8990879261442634\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_true.label, y_pred.prediction))\n",
        "print(accuracy_score(y_true.label, y_pred.prediction))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSSB-ZHJIPQb"
      },
      "source": [
        "### LogReg with TFIDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmWR-GnOIPQc",
        "outputId": "5ec0d12e-b2b8-4cc3-d883-234dabef147a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120000"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "from pyspark.ml.feature import HashingTF, IDF\n",
        "\n",
        "hashingTF = HashingTF(inputCol=\"token_features\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
        "\n",
        "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
        "\n",
        "nlp_pipeline_tf = Pipeline(\n",
        "    stages=[document_assembler, \n",
        "            tokenizer,\n",
        "            normalizer,\n",
        "            stopwords_cleaner, \n",
        "            stemmer, \n",
        "            finisher,\n",
        "            hashingTF,\n",
        "           idf,\n",
        "           label_stringIdx])\n",
        "\n",
        "nlp_model_tf = nlp_pipeline_tf.fit(newsDF)\n",
        "\n",
        "processed_tf = nlp_model_tf.transform(newsDF)\n",
        "\n",
        "processed_tf.count()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RHs0RjOIPQe",
        "outputId": "c5c5d0ef-7cb4-41f5-9cde-ccf9dc36f076"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+-----+\n",
            "|         description|            features|label|\n",
            "+--------------------+--------------------+-----+\n",
            "| Short sellers, W...|(10000,[25,625,66...|  1.0|\n",
            "| Private investme...|(10000,[82,111,15...|  1.0|\n",
            "| Soaring crude pr...|(10000,[410,1097,...|  1.0|\n",
            "| Authorities have...|(10000,[1611,1637...|  1.0|\n",
            "| Tearaway world o...|(10000,[1150,1427...|  1.0|\n",
            "| Stocks ended sli...|(10000,[332,410,6...|  1.0|\n",
            "| Assets of the na...|(10000,[1442,1788...|  1.0|\n",
            "| Retail sales bou...|(10000,[25,117,97...|  1.0|\n",
            "|\" After earning a...|(10000,[114,643,7...|  1.0|\n",
            "| Short sellers, W...|(10000,[25,625,66...|  1.0|\n",
            "| Soaring crude pr...|(10000,[410,1097,...|  1.0|\n",
            "| OPEC can do noth...|(10000,[616,904,1...|  1.0|\n",
            "| Non OPEC oil exp...|(10000,[616,2224,...|  1.0|\n",
            "| WASHINGTON/NEW Y...|(10000,[351,360,3...|  1.0|\n",
            "| The dollar tumbl...|(10000,[359,456,9...|  1.0|\n",
            "|If you think you ...|(10000,[1041,1564...|  1.0|\n",
            "|The purchasing po...|(10000,[2198,4091...|  1.0|\n",
            "|There is little c...|(10000,[410,432,5...|  1.0|\n",
            "|The US trade defi...|(10000,[332,2286,...|  1.0|\n",
            "|Oil giant Shell c...|(10000,[463,868,2...|  1.0|\n",
            "+--------------------+--------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# set seed for reproducibility\n",
        "processed_tf.select('description','features','label').show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHewYwjbIPQg",
        "outputId": "39087bb3-a1a3-44a6-f53e-ad7465f52952"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Dataset Count: 84038\n",
            "Test Dataset Count: 35962\n"
          ]
        }
      ],
      "source": [
        "(trainingData, testData) = processed_tf.randomSplit([0.7, 0.3], seed = 100)\n",
        "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
        "print(\"Test Dataset Count: \" + str(testData.count()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcCnp1PrIPQj",
        "outputId": "f15a9de7-007b-40a0-e67b-7e6df6885dfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------+--------+------------------------------+-----+----------+\n",
            "|                   description|category|                   probability|label|prediction|\n",
            "+------------------------------+--------+------------------------------+-----+----------+\n",
            "|Novell brings updated kerne...|Business|[0.9999995229578786,2.86181...|  1.0|       0.0|\n",
            "|F5 bolsters firewall family...|Sci/Tech|[0.9999631964683853,2.87934...|  0.0|       0.0|\n",
            "|\\\\Sam blogs about his wiki ...|Sci/Tech|[0.9999591803496525,3.00816...|  0.0|       0.0|\n",
            "| Cray taps Linux for more a...|Sci/Tech|[0.99988175049369,1.0958016...|  0.0|       0.0|\n",
            "| At a special music event o...|Sci/Tech|[0.9997199938921201,2.03591...|  0.0|       0.0|\n",
            "| You Software Inc. announce...|Sci/Tech|[0.9996235826906964,5.33405...|  0.0|       0.0|\n",
            "|MOFFETT FIELD, CALIFORNIA -...|Sci/Tech|[0.9995490457561748,2.09063...|  0.0|       0.0|\n",
            "|Sun Microsystems will integ...|Sci/Tech|[0.9990914778205654,2.87415...|  0.0|       0.0|\n",
            "| Microsoft (Nasdaq: MSFT) l...|Sci/Tech|[0.9987708507466153,8.71434...|  0.0|       0.0|\n",
            "|\\\\I've blogged before  abou...|Sci/Tech|[0.9987626784524191,7.79098...|  0.0|       0.0|\n",
            "+------------------------------+--------+------------------------------+-----+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "lrModel_tf = lr.fit(trainingData)\n",
        "\n",
        "predictions_tf = lrModel_tf.transform(testData)\n",
        "\n",
        "predictions_tf.select(\"description\",\"category\",\"probability\",\"label\",\"prediction\") \\\n",
        "    .orderBy(\"probability\", ascending=False) \\\n",
        "    .show(n = 10, truncate = 30)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8EH6P4-IPQm",
        "outputId": "b59455fc-6f2d-4e05-f132-b6cf9b4a954c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.85      0.85      0.85      8950\n",
            "         1.0       0.85      0.85      0.85      8908\n",
            "         2.0       0.91      0.88      0.90      9018\n",
            "         3.0       0.94      0.96      0.95      9086\n",
            "\n",
            "    accuracy                           0.89     35962\n",
            "   macro avg       0.89      0.89      0.89     35962\n",
            "weighted avg       0.89      0.89      0.89     35962\n",
            "\n",
            "0.8877148100773038\n"
          ]
        }
      ],
      "source": [
        "y_true = predictions_tf.select(\"label\")\n",
        "y_true = y_true.toPandas()\n",
        "\n",
        "y_pred = predictions_tf.select(\"prediction\")\n",
        "y_pred = y_pred.toPandas()\n",
        "\n",
        "print(classification_report(y_true.label, y_pred.prediction))\n",
        "print(accuracy_score(y_true.label, y_pred.prediction))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bdwtu_9IPQp"
      },
      "source": [
        "### Random Forest with TFIDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILNZ4-vPIPQp"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(labelCol=\"label\", \\\n",
        "                            featuresCol=\"features\", \\\n",
        "                            numTrees = 100, \\\n",
        "                            maxDepth = 4, \\\n",
        "                            maxBins = 32)\n",
        "\n",
        "# Train model with Training Data\n",
        "rfModel = rf.fit(trainingData)\n",
        "predictions_rf = rfModel.transform(testData)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pY9EQY1tIPQr",
        "outputId": "bf44a208-d0ca-4416-d96f-b40db3b5f88a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------+--------+------------------------------+-----+----------+\n",
            "|                   description|category|                   probability|label|prediction|\n",
            "+------------------------------+--------+------------------------------+-----+----------+\n",
            "| Microsoft Corp., hoping to...|Sci/Tech|[0.38025427051503,0.2615110...|  0.0|       0.0|\n",
            "| You Software Inc. announce...|Sci/Tech|[0.37690896168759835,0.2343...|  0.0|       0.0|\n",
            "|In a bid to dethrone Apple ...|Sci/Tech|[0.3744373024799478,0.23155...|  0.0|       0.0|\n",
            "|Microsoft is expected to en...|Sci/Tech|[0.3742426420072038,0.23816...|  0.0|       0.0|\n",
            "| On the face of things, Mic...|Sci/Tech|[0.37181825361445076,0.2616...|  0.0|       0.0|\n",
            "| Microsoft Corp. launched a...|Sci/Tech|[0.3709883982206899,0.26160...|  0.0|       0.0|\n",
            "|APPLE Computer has extended...|Sci/Tech|[0.3626937307330564,0.23037...|  0.0|       0.0|\n",
            "|Microsoft will begin offeri...|Sci/Tech|[0.362291694911747,0.221690...|  0.0|       0.0|\n",
            "|com December 2, 2004, 7:58 ...|Sci/Tech|[0.3602885673011446,0.25017...|  0.0|       0.0|\n",
            "|Google Inc. (GOOG)'s long-a...|Sci/Tech|[0.3598408259912352,0.28224...|  0.0|       0.0|\n",
            "+------------------------------+--------+------------------------------+-----+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "predictions_rf.select(\"description\",\"category\",\"probability\",\"label\",\"prediction\") \\\n",
        "    .orderBy(\"probability\", ascending=False) \\\n",
        "    .show(n = 10, truncate = 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_vXMkvuIPQu",
        "outputId": "46eedfb5-63c4-4137-bfdb-f0c763d77a54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.73      0.63      0.68      8950\n",
            "         1.0       0.74      0.67      0.71      8908\n",
            "         2.0       0.81      0.74      0.77      9018\n",
            "         3.0       0.69      0.91      0.79      9086\n",
            "\n",
            "    accuracy                           0.74     35962\n",
            "   macro avg       0.75      0.74      0.74     35962\n",
            "weighted avg       0.75      0.74      0.74     35962\n",
            "\n",
            "0.739669651298593\n"
          ]
        }
      ],
      "source": [
        "y_true = predictions_rf.select(\"label\")\n",
        "y_true = y_true.toPandas()\n",
        "\n",
        "y_pred = predictions_rf.select(\"prediction\")\n",
        "y_pred = y_pred.toPandas()\n",
        "\n",
        "print(classification_report(y_true.label, y_pred.prediction))\n",
        "print(accuracy_score(y_true.label, y_pred.prediction))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzoo98_nIPQx"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3tdY1_oIPQ0"
      },
      "source": [
        "## LogReg with Spark NLP Glove Word Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GVKps1mIPQ0",
        "outputId": "f4ca7ad1-75ff-46bb-80c4-cd8b0ae0acae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "glove_100d download started this may take some time.\n",
            "Approximate size to download 145.3 MB\n",
            "[OK!]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120000"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "document_assembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"description\") \\\n",
        "    .setOutputCol(\"document\")\n",
        "    \n",
        "tokenizer = Tokenizer() \\\n",
        "  .setInputCols([\"document\"]) \\\n",
        "  .setOutputCol(\"token\")\n",
        "    \n",
        "normalizer = Normalizer() \\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"normalized\")\n",
        "\n",
        "stopwords_cleaner = StopWordsCleaner()\\\n",
        "      .setInputCols(\"normalized\")\\\n",
        "      .setOutputCol(\"cleanTokens\")\\\n",
        "      .setCaseSensitive(False)\n",
        "\n",
        "glove_embeddings = WordEmbeddingsModel().pretrained() \\\n",
        " .setInputCols([\"document\",'cleanTokens'])\\\n",
        " .setOutputCol(\"embeddings\")\\\n",
        " .setCaseSensitive(False)\n",
        "\n",
        "embeddingsSentence = SentenceEmbeddings() \\\n",
        "      .setInputCols([\"document\", \"embeddings\"]) \\\n",
        "      .setOutputCol(\"sentence_embeddings\") \\\n",
        "      .setPoolingStrategy(\"AVERAGE\")\n",
        "    \n",
        "embeddings_finisher = EmbeddingsFinisher() \\\n",
        "    .setInputCols([\"sentence_embeddings\"]) \\\n",
        "    .setOutputCols([\"finished_sentence_embeddings\"]) \\\n",
        "    .setOutputAsVector(True)\\\n",
        "    .setCleanAnnotations(False)\n",
        "\n",
        "explodeVectors = SQLTransformer(statement=\n",
        "      \"SELECT EXPLODE(finished_sentence_embeddings) AS features, * FROM __THIS__\")\n",
        "\n",
        "label_stringIdx = StringIndexer(inputCol = \"category\", outputCol = \"label\")\n",
        "\n",
        "\n",
        "nlp_pipeline_w2v = Pipeline(\n",
        "    stages=[document_assembler, \n",
        "            tokenizer,\n",
        "            normalizer,\n",
        "            stopwords_cleaner, \n",
        "            glove_embeddings,\n",
        "            embeddingsSentence,\n",
        "            embeddings_finisher,\n",
        "            explodeVectors,\n",
        "           label_stringIdx])\n",
        "\n",
        "nlp_model_w2v = nlp_pipeline_w2v.fit(newsDF)\n",
        "\n",
        "processed_w2v = nlp_model_w2v.transform(newsDF)\n",
        "\n",
        "processed_w2v.count()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLVVHJEHIPQ3"
      },
      "outputs": [],
      "source": [
        "#processed_w2v.select('finished_embeddings').take(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIqz6Pi6IPQ6"
      },
      "outputs": [],
      "source": [
        "#processed_w2v.select(\"finished_embeddings\").show(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64DFF7JHIPQ9",
        "outputId": "6fbaff0a-b71a-4713-c9d1-e084e1606298"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(finished_sentence_embeddings=[DenseVector([-0.1557, 0.196, 0.1099, -0.3089, 0.16, 0.1672, -0.4649, -0.1101, -0.053, -0.1551, 0.0327, 0.0772, 0.1494, -0.1865, 0.1155, -0.0597, 0.0234, -0.0451, 0.2361, -0.0089, 0.3358, 0.0444, 0.0088, -0.1453, 0.2289, 0.0914, -0.1665, -0.3726, 0.1892, 0.121, 0.1993, -0.0239, -0.1346, 0.1159, 0.2086, 0.1285, 0.068, 0.1372, 0.3153, -0.1934, 0.0257, -0.226, -0.0984, 0.1139, 0.1413, -0.3743, 0.072, 0.1403, 0.251, -0.3106, 0.1709, -0.0697, -0.0554, 0.5123, -0.1873, -1.7784, 0.0295, 0.1014, 0.9268, 0.2129, -0.1354, 0.5739, -0.0679, 0.461, 0.4216, 0.0225, 0.4456, -0.2462, 0.1411, -0.3258, 0.0025, 0.0114, -0.3895, -0.1106, -0.261, 0.0147, 0.0781, 0.1268, -0.2042, -0.2278, 0.5096, 0.1539, -0.3515, -0.0102, -0.7003, -0.3872, -0.1668, -0.2405, -0.0766, 0.1396, -0.0592, -0.1568, -0.1606, -0.1371, -0.684, -0.2549, -0.1541, 0.1536, 0.2715, 0.3342])])]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "processed_w2v.select('finished_sentence_embeddings').take(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0JRYsk0mIPQ_"
      },
      "outputs": [],
      "source": [
        "# IF SQLTransformer IS NOT USED INSIDE THE PIPELINE, WE CAN EXPLODE OUTSIDE\n",
        "from pyspark.sql.functions import explode\n",
        "\n",
        "# processed_w2v= processed_w2v.withColumn(\"features\", explode(processed_w2v.finished_sentence_embeddings))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWp3CA_kIPRB",
        "outputId": "78db49b2-c804-48ef-8961-146cc09aab11"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(features=DenseVector([-0.1557, 0.196, 0.1099, -0.3089, 0.16, 0.1672, -0.4649, -0.1101, -0.053, -0.1551, 0.0327, 0.0772, 0.1494, -0.1865, 0.1155, -0.0597, 0.0234, -0.0451, 0.2361, -0.0089, 0.3358, 0.0444, 0.0088, -0.1453, 0.2289, 0.0914, -0.1665, -0.3726, 0.1892, 0.121, 0.1993, -0.0239, -0.1346, 0.1159, 0.2086, 0.1285, 0.068, 0.1372, 0.3153, -0.1934, 0.0257, -0.226, -0.0984, 0.1139, 0.1413, -0.3743, 0.072, 0.1403, 0.251, -0.3106, 0.1709, -0.0697, -0.0554, 0.5123, -0.1873, -1.7784, 0.0295, 0.1014, 0.9268, 0.2129, -0.1354, 0.5739, -0.0679, 0.461, 0.4216, 0.0225, 0.4456, -0.2462, 0.1411, -0.3258, 0.0025, 0.0114, -0.3895, -0.1106, -0.261, 0.0147, 0.0781, 0.1268, -0.2042, -0.2278, 0.5096, 0.1539, -0.3515, -0.0102, -0.7003, -0.3872, -0.1668, -0.2405, -0.0766, 0.1396, -0.0592, -0.1568, -0.1606, -0.1371, -0.684, -0.2549, -0.1541, 0.1536, 0.2715, 0.3342]))]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "processed_w2v.select(\"features\").take(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMN2OwXlIPRF",
        "outputId": "9b777fbc-f1e1-4e11-9bc5-cb68822b77fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(features=DenseVector([-0.1557, 0.196, 0.1099, -0.3089, 0.16, 0.1672, -0.4649, -0.1101, -0.053, -0.1551, 0.0327, 0.0772, 0.1494, -0.1865, 0.1155, -0.0597, 0.0234, -0.0451, 0.2361, -0.0089, 0.3358, 0.0444, 0.0088, -0.1453, 0.2289, 0.0914, -0.1665, -0.3726, 0.1892, 0.121, 0.1993, -0.0239, -0.1346, 0.1159, 0.2086, 0.1285, 0.068, 0.1372, 0.3153, -0.1934, 0.0257, -0.226, -0.0984, 0.1139, 0.1413, -0.3743, 0.072, 0.1403, 0.251, -0.3106, 0.1709, -0.0697, -0.0554, 0.5123, -0.1873, -1.7784, 0.0295, 0.1014, 0.9268, 0.2129, -0.1354, 0.5739, -0.0679, 0.461, 0.4216, 0.0225, 0.4456, -0.2462, 0.1411, -0.3258, 0.0025, 0.0114, -0.3895, -0.1106, -0.261, 0.0147, 0.0781, 0.1268, -0.2042, -0.2278, 0.5096, 0.1539, -0.3515, -0.0102, -0.7003, -0.3872, -0.1668, -0.2405, -0.0766, 0.1396, -0.0592, -0.1568, -0.1606, -0.1371, -0.684, -0.2549, -0.1541, 0.1536, 0.2715, 0.3342]))]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "processed_w2v.select(\"features\").take(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViXxQrhSIPRH",
        "outputId": "83659a18-6279-4fe0-b89e-df9d1c168e6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+-----+\n",
            "|         description|            features|label|\n",
            "+--------------------+--------------------+-----+\n",
            "| Short sellers, W...|[-0.1556767076253...|  1.0|\n",
            "| Private investme...|[-0.0144653050228...|  1.0|\n",
            "| Soaring crude pr...|[0.10348732769489...|  1.0|\n",
            "| Authorities have...|[-0.0355810523033...|  1.0|\n",
            "| Tearaway world o...|[0.00647281948477...|  1.0|\n",
            "| Stocks ended sli...|[0.20069395005702...|  1.0|\n",
            "| Assets of the na...|[0.38012433052062...|  1.0|\n",
            "| Retail sales bou...|[0.20352847874164...|  1.0|\n",
            "|\" After earning a...|[0.13536226749420...|  1.0|\n",
            "| Short sellers, W...|[-0.1556767076253...|  1.0|\n",
            "| Soaring crude pr...|[0.10348732769489...|  1.0|\n",
            "| OPEC can do noth...|[0.20307321846485...|  1.0|\n",
            "| Non OPEC oil exp...|[0.09010648727416...|  1.0|\n",
            "| WASHINGTON/NEW Y...|[0.10887209326028...|  1.0|\n",
            "| The dollar tumbl...|[0.05723679438233...|  1.0|\n",
            "|If you think you ...|[0.11463439464569...|  1.0|\n",
            "|The purchasing po...|[0.05890964344143...|  1.0|\n",
            "|There is little c...|[0.11162020266056...|  1.0|\n",
            "|The US trade defi...|[0.09235177189111...|  1.0|\n",
            "|Oil giant Shell c...|[0.01885983347892...|  1.0|\n",
            "+--------------------+--------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "processed_w2v.select('description','features','label').show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vx__5MOLIPRK",
        "outputId": "ca657b29-9c24-40de-db80-201a3e7cc4a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Dataset Count: 84038\n",
            "Test Dataset Count: 35962\n"
          ]
        }
      ],
      "source": [
        "# set seed for reproducibility\n",
        "(trainingData, testData) = processed_w2v.randomSplit([0.7, 0.3], seed = 100)\n",
        "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
        "print(\"Test Dataset Count: \" + str(testData.count()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FK6x3ljGIPRO"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import udf\n",
        "\n",
        "@udf(\"long\")\n",
        "def num_nonzeros(v):\n",
        "    return v.numNonzeros()\n",
        "\n",
        "testData = testData.where(num_nonzeros(\"features\") != 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S61P66r6IPRP",
        "outputId": "0c846f6b-bbf9-4eef-b7bf-d8994e107f30"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35962"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "testData.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdbLwEsnIPRR"
      },
      "outputs": [],
      "source": [
        "lrModel_w2v = lr.fit(trainingData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoSYCqDjIPRT",
        "outputId": "4d98591d-c352-46a2-e4b8-22b8a4800a19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------+--------+------------------------------+-----+----------+\n",
            "|                   description|category|                   probability|label|prediction|\n",
            "+------------------------------+--------+------------------------------+-----+----------+\n",
            "|The KDE Project has release...|Sci/Tech|[0.9993026934526253,5.26811...|  0.0|       0.0|\n",
            "| Users can now access searc...|Sci/Tech|[0.9984190388827833,0.00112...|  0.0|       0.0|\n",
            "|\" The Xbox version of \"\"Doom 3|Sci/Tech|[0.9978700979929389,8.61016...|  0.0|       0.0|\n",
            "|\" The Xbox version of \"\"Doom 3|Sci/Tech|[0.9978700979929389,8.61016...|  0.0|       0.0|\n",
            "|\" The Xbox version of \"\"Doom 3|Sci/Tech|[0.9978700979929389,8.61016...|  0.0|       0.0|\n",
            "|With Google Desktop Search,...|Sci/Tech|[0.9966360633091306,0.00214...|  0.0|       0.0|\n",
            "|Google has finally announce...|Business|[0.996501742592862,0.002382...|  1.0|       0.0|\n",
            "|But users of the popular co...|Sci/Tech|[0.9963135491275907,0.00278...|  0.0|       0.0|\n",
            "|\" Users of Internet \"\"peer ...|Sci/Tech|[0.9960517044794686,0.00345...|  0.0|       0.0|\n",
            "|The new patches apply to a ...|Sci/Tech|[0.9959615644629484,0.00344...|  0.0|       0.0|\n",
            "+------------------------------+--------+------------------------------+-----+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "predictions_w2v = lrModel_w2v.transform(testData)\n",
        "\n",
        "predictions_w2v.select(\"description\",\"category\",\"probability\",\"label\",\"prediction\") \\\n",
        "    .orderBy(\"probability\", ascending=False) \\\n",
        "    .show(n = 10, truncate = 30)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FiCz7TZ8IPRV"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2WQ3rZmIPRX",
        "outputId": "3b13b121-5fed-4a68-c14f-62b9226f32d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.82      0.81      0.81      8902\n",
            "         1.0       0.82      0.83      0.82      9072\n",
            "         2.0       0.88      0.87      0.87      9006\n",
            "         3.0       0.93      0.95      0.94      8982\n",
            "\n",
            "    accuracy                           0.86     35962\n",
            "   macro avg       0.86      0.86      0.86     35962\n",
            "weighted avg       0.86      0.86      0.86     35962\n",
            "\n",
            "0.8633835715477448\n"
          ]
        }
      ],
      "source": [
        "y_true = predictions_w2v.select(\"label\")\n",
        "y_true = y_true.toPandas()\n",
        "\n",
        "y_pred = predictions_w2v.select(\"prediction\")\n",
        "y_pred = y_pred.toPandas()\n",
        "\n",
        "print(classification_report(y_true.label, y_pred.prediction))\n",
        "print(accuracy_score(y_true.label, y_pred.prediction))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idNRXJJiIPRa",
        "outputId": "e0947994-4199-41fa-ab1b-91b4bad18798"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------+--------------------------------------------------+\n",
            "|                                       description|                                            result|\n",
            "+--------------------------------------------------+--------------------------------------------------+\n",
            "| Short sellers, Wall Street's dwindling band of...|[Short, sellers, Wall, Streets, dwindling, band...|\n",
            "| Private investment firm Carlyle Group, which h...|[Private, investment, firm, Carlyle, Group, rep...|\n",
            "| Soaring crude prices plus worries about the ec...|[Soaring, crude, prices, plus, worries, economy...|\n",
            "| Authorities have halted oil export flows from ...|[Authorities, halted, oil, export, flows, main,...|\n",
            "| Tearaway world oil prices, toppling records an...|[Tearaway, world, oil, prices, toppling, record...|\n",
            "| Stocks ended slightly higher on Friday but sta...|[Stocks, ended, slightly, higher, Friday, staye...|\n",
            "| Assets of the nation's retail money market mut...|[Assets, nations, retail, money, market, mutual...|\n",
            "| Retail sales bounced back a bit in July, and n...|[Retail, sales, bounced, back, bit, July, new, ...|\n",
            "|\" After earning a PH.D. in Sociology, Danny Baz...|[earning, PHD, Sociology, Danny, Bazil, Riley, ...|\n",
            "| Short sellers, Wall Street's dwindling  band o...|[Short, sellers, Wall, Streets, dwindling, band...|\n",
            "| Soaring crude prices plus worries  about the e...|[Soaring, crude, prices, plus, worries, economy...|\n",
            "| OPEC can do nothing to douse scorching  oil pr...|[OPEC, nothing, douse, scorching, oil, prices, ...|\n",
            "| Non OPEC oil exporters should consider  increa...|[Non, OPEC, oil, exporters, consider, increasin...|\n",
            "| WASHINGTON/NEW YORK (Reuters) - The auction fo...|[WASHINGTONNEW, YORK, Reuters, auction, Google,...|\n",
            "| The dollar tumbled broadly on Friday  after da...|[dollar, tumbled, broadly, Friday, data, showin...|\n",
            "|If you think you may need to help your elderly ...|[think, may, need, help, elderly, relatives, fi...|\n",
            "|The purchasing power of kids is a big part of w...|[purchasing, power, kids, big, part, backtoscho...|\n",
            "|There is little cause for celebration in the st...|[little, cause, celebration, stock, market, day...|\n",
            "|The US trade deficit has exploded 19 to a recor...|[US, trade, deficit, exploded, record, bn, oil,...|\n",
            "|Oil giant Shell could be bracing itself for a t...|[Oil, giant, Shell, bracing, takeover, attempt,...|\n",
            "+--------------------------------------------------+--------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "processed_w2v.select('description','cleanTokens.result').show(truncate=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6X5ppwOIPRf"
      },
      "source": [
        "## LogReg with Spark NLP Bert Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdF5eFJcIPRf",
        "outputId": "3a6cdf89-34c4-46e2-bf5d-89db87e56b09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_base_cased download started this may take some time.\n",
            "Approximate size to download 389.2 MB\n",
            "[OK!]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120000"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "document_assembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"description\") \\\n",
        "    .setOutputCol(\"document\")\n",
        "    \n",
        "tokenizer = Tokenizer() \\\n",
        "  .setInputCols([\"document\"]) \\\n",
        "  .setOutputCol(\"token\")\n",
        "    \n",
        "normalizer = Normalizer() \\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"normalized\")\n",
        "\n",
        "stopwords_cleaner = StopWordsCleaner()\\\n",
        "      .setInputCols(\"normalized\")\\\n",
        "      .setOutputCol(\"cleanTokens\")\\\n",
        "      .setCaseSensitive(False)\n",
        "\n",
        "bert_embeddings = BertEmbeddings\\\n",
        " .pretrained('bert_base_cased', 'en') \\\n",
        " .setInputCols([\"document\",'cleanTokens'])\\\n",
        " .setOutputCol(\"bert\")\\\n",
        " .setCaseSensitive(False)\\\n",
        " .setPoolingLayer(0)\n",
        "\n",
        "embeddingsSentence = SentenceEmbeddings() \\\n",
        "      .setInputCols([\"document\", \"bert\"]) \\\n",
        "      .setOutputCol(\"sentence_embeddings\") \\\n",
        "      .setPoolingStrategy(\"AVERAGE\")\n",
        "    \n",
        "embeddings_finisher = EmbeddingsFinisher() \\\n",
        "    .setInputCols([\"sentence_embeddings\"]) \\\n",
        "    .setOutputCols([\"finished_sentence_embeddings\"]) \\\n",
        "    .setOutputAsVector(True)\\\n",
        "    .setCleanAnnotations(False)\n",
        "\n",
        "label_stringIdx = StringIndexer(inputCol = \"category\", outputCol = \"label\")\n",
        "\n",
        "\n",
        "nlp_pipeline_bert = Pipeline(\n",
        "    stages=[document_assembler, \n",
        "            tokenizer,\n",
        "            normalizer,\n",
        "            stopwords_cleaner, \n",
        "            bert_embeddings,\n",
        "            embeddingsSentence,\n",
        "            embeddings_finisher,\n",
        "           label_stringIdx])\n",
        "\n",
        "nlp_model_bert = nlp_pipeline_bert.fit(newsDF)\n",
        "\n",
        "processed_bert = nlp_model_bert.transform(newsDF)\n",
        "\n",
        "processed_bert.count()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7g2Yk5vdIPRh",
        "outputId": "e3f1f38e-37b0-40b3-dc54-13e2df2b658d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+-----+\n",
            "|         description|            features|label|\n",
            "+--------------------+--------------------+-----+\n",
            "| Short sellers, W...|[-0.2046198099851...|  1.0|\n",
            "| Private investme...|[0.05162287876009...|  1.0|\n",
            "| Soaring crude pr...|[-0.3564318418502...|  1.0|\n",
            "| Authorities have...|[0.07367337495088...|  1.0|\n",
            "| Tearaway world o...|[0.27237433195114...|  1.0|\n",
            "| Stocks ended sli...|[-0.0425911881029...|  1.0|\n",
            "| Assets of the na...|[0.12972426414489...|  1.0|\n",
            "| Retail sales bou...|[0.19162152707576...|  1.0|\n",
            "|\" After earning a...|[0.07279182225465...|  1.0|\n",
            "| Short sellers, W...|[-0.2046198099851...|  1.0|\n",
            "| Soaring crude pr...|[-0.3564318418502...|  1.0|\n",
            "| OPEC can do noth...|[-0.0903253182768...|  1.0|\n",
            "| Non OPEC oil exp...|[0.33865353465080...|  1.0|\n",
            "| WASHINGTON/NEW Y...|[0.26189467310905...|  1.0|\n",
            "| The dollar tumbl...|[0.32719594240188...|  1.0|\n",
            "|If you think you ...|[0.17194975912570...|  1.0|\n",
            "|The purchasing po...|[-0.1187076270580...|  1.0|\n",
            "|There is little c...|[0.00563184311613...|  1.0|\n",
            "|The US trade defi...|[0.33918958902359...|  1.0|\n",
            "|Oil giant Shell c...|[-0.0870998427271...|  1.0|\n",
            "+--------------------+--------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import explode\n",
        "\n",
        "processed_bert= processed_bert.withColumn(\"features\", explode(processed_bert.finished_sentence_embeddings))\n",
        "\n",
        "processed_bert.select('description','features','label').show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqDwRWZbIPRk",
        "outputId": "467bb243-df6b-4edc-cc62-b1797a87bd1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Dataset Count: 84038\n",
            "Test Dataset Count: 35962\n"
          ]
        }
      ],
      "source": [
        "# set seed for reproducibility\n",
        "(trainingData, testData) = processed_bert.randomSplit([0.7, 0.3], seed = 100)\n",
        "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
        "print(\"Test Dataset Count: \" + str(testData.count()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "kSe7wzqfIPRm",
        "outputId": "49cf7249-adcc-4a85-fbe4-53b5a3792a97"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-670f69aeeaee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxIter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregParam\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melasticNetParam\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlrModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainingData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \"\"\"\n\u001b[1;32m    291\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\n",
        "\n",
        "lrModel = lr.fit(trainingData)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTRXE2TrIPRo"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import udf\n",
        "\n",
        "@udf(\"long\")\n",
        "def num_nonzeros(v):\n",
        "    return v.numNonzeros()\n",
        "\n",
        "testData = testData.where(num_nonzeros(\"features\") != 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_c43W5PjIPRq"
      },
      "outputs": [],
      "source": [
        "predictions = lrModel.transform(testData)\n",
        "\n",
        "predictions.select(\"description\",\"category\",\"probability\",\"label\",\"prediction\") \\\n",
        "    .orderBy(\"probability\", ascending=False) \\\n",
        "    .show(n = 10, truncate = 30)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "buAz91hDIPRs"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "df = predictions.select('description','category','label','prediction').toPandas()\n",
        "\n",
        "print(classification_report(df.label, df.prediction))\n",
        "print(accuracy_score(df.label, df.prediction))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSCxUSkmIPRu"
      },
      "source": [
        "## LogReg with ELMO Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_pCzKheIPRv"
      },
      "outputs": [],
      "source": [
        "document_assembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"description\") \\\n",
        "    .setOutputCol(\"document\")\n",
        "    \n",
        "tokenizer = Tokenizer() \\\n",
        "  .setInputCols([\"document\"]) \\\n",
        "  .setOutputCol(\"token\")\n",
        "    \n",
        "normalizer = Normalizer() \\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"normalized\")\n",
        "\n",
        "stopwords_cleaner = StopWordsCleaner()\\\n",
        "      .setInputCols(\"normalized\")\\\n",
        "      .setOutputCol(\"cleanTokens\")\\\n",
        "      .setCaseSensitive(False)\n",
        "\n",
        "elmo_embeddings = ElmoEmbeddings.load('/Users/vkocaman/cache_pretrained/elmo_en_2.4.0_2.4_1580488815299')\\\n",
        "      .setPoolingLayer(\"word_emb\")\\\n",
        "      .setInputCols([\"document\",'cleanTokens'])\\\n",
        "      .setOutputCol(\"elmo\")\n",
        "\n",
        "embeddingsSentence = SentenceEmbeddings() \\\n",
        "      .setInputCols([\"document\", \"elmo\"]) \\\n",
        "      .setOutputCol(\"sentence_embeddings\") \\\n",
        "      .setPoolingStrategy(\"AVERAGE\")\n",
        "    \n",
        "embeddings_finisher = EmbeddingsFinisher() \\\n",
        "    .setInputCols([\"sentence_embeddings\"]) \\\n",
        "    .setOutputCols([\"finished_sentence_embeddings\"]) \\\n",
        "    .setOutputAsVector(True)\\\n",
        "    .setCleanAnnotations(False)\n",
        "\n",
        "label_stringIdx = StringIndexer(inputCol = \"category\", outputCol = \"label\")\n",
        "\n",
        "\n",
        "nlp_pipeline_elmo = Pipeline(\n",
        "    stages=[document_assembler, \n",
        "            tokenizer,\n",
        "            normalizer,\n",
        "            stopwords_cleaner, \n",
        "            elmo_embeddings,\n",
        "            embeddingsSentence,\n",
        "            embeddings_finisher,\n",
        "           label_stringIdx])\n",
        "\n",
        "nlp_model_elmo = nlp_pipeline_elmo.fit(newsDF)\n",
        "\n",
        "processed_elmo = nlp_model_elmo.transform(newsDF)\n",
        "\n",
        "processed_elmo.count()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vk7XGN5IPRx"
      },
      "outputs": [],
      "source": [
        "(trainingData, testData) = newsDF.randomSplit([0.7, 0.3], seed = 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-VCL5iOIPRz"
      },
      "outputs": [],
      "source": [
        "processed_trainingData = nlp_model_elmo.transform(trainingData)\n",
        "\n",
        "processed_trainingData.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLxq_udOIPR1"
      },
      "outputs": [],
      "source": [
        "processed_testData = nlp_model_elmo.transform(testData)\n",
        "\n",
        "processed_testData.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWqgBJmKIPR2"
      },
      "outputs": [],
      "source": [
        "processed_trainingData.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3W9kceqIPR4"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "processed_testData= processed_testData.withColumn(\"features\", explode(processed_testData.finished_sentence_embeddings))\n",
        "\n",
        "processed_trainingData= processed_trainingData.withColumn(\"features\", explode(processed_trainingData.finished_sentence_embeddings))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hY8z7srJIPR6"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import udf\n",
        "\n",
        "@udf(\"long\")\n",
        "def num_nonzeros(v):\n",
        "    return v.numNonzeros()\n",
        "\n",
        "processed_testData = processed_testData.where(num_nonzeros(\"features\") != 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lyqIOMbsIPR8"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\n",
        "\n",
        "lrModel = lr.fit(processed_trainingData)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D04iWWPMIPR9"
      },
      "outputs": [],
      "source": [
        "processed_trainingData.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vS2_xs3ZIPSA"
      },
      "outputs": [],
      "source": [
        "\n",
        "predictions = lrModel.transform(processed_testData)\n",
        "\n",
        "predictions.select(\"description\",\"category\",\"probability\",\"label\",\"prediction\") \\\n",
        "    .orderBy(\"probability\", ascending=False) \\\n",
        "    .show(n = 10, truncate = 30)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3lz8IFhIPSC"
      },
      "outputs": [],
      "source": [
        "df = predictions.select('description','category','label','prediction').toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrJtqnTcIPSD"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7eEgmPDWIPSF"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JS3R3knIPSI"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "print(classification_report(df.label, df.prediction))\n",
        "print(accuracy_score(df.label, df.prediction))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YpFN8zBIPSJ"
      },
      "source": [
        "## LogReg with Universal Sentence Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4YxWiKdIPSK"
      },
      "outputs": [],
      "source": [
        "document_assembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"description\") \\\n",
        "    .setOutputCol(\"document\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJd8yf0cIPSL"
      },
      "outputs": [],
      "source": [
        "\n",
        "useEmbeddings = UniversalSentenceEncoder.load('/Users/vkocaman/cache_pretrained/tfhub_use_en_2.4.0_2.4_1580582893733')\\\n",
        "      .setInputCols(\"document\")\\\n",
        "      .setOutputCol(\"use_embeddings\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMO7CCMpIPSM"
      },
      "outputs": [],
      "source": [
        "\n",
        "embeddings_finisher = EmbeddingsFinisher() \\\n",
        "    .setInputCols([\"use_embeddings\"]) \\\n",
        "    .setOutputCols([\"finished_use_embeddings\"]) \\\n",
        "    .setOutputAsVector(True)\\\n",
        "    .setCleanAnnotations(False)\n",
        "\n",
        "label_stringIdx = StringIndexer(inputCol = \"category\", outputCol = \"label\")\n",
        "\n",
        "use_pipeline = Pipeline(\n",
        "      stages=[\n",
        "        document_assembler,\n",
        "          useEmbeddings,\n",
        "        embeddings_finisher,\n",
        "      label_stringIdx]\n",
        "      )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXnlj3diIPSN"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30FApLSbIPSP"
      },
      "outputs": [],
      "source": [
        "use_df = use_pipeline.fit(newsDF).transform(newsDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbiA3moMIPSR"
      },
      "outputs": [],
      "source": [
        "use_df.select('finished_use_embeddings').show(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9nI3EXthIPST"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import explode\n",
        "\n",
        "use_df= use_df.withColumn(\"features\", explode(use_df.finished_use_embeddings))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PD9vNF2KIPSV"
      },
      "outputs": [],
      "source": [
        "use_df.show(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_VHl1FFIPSX"
      },
      "outputs": [],
      "source": [
        "# set seed for reproducibility\n",
        "(trainingData, testData) = use_df.randomSplit([0.7, 0.3], seed = 100)\n",
        "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
        "print(\"Test Dataset Count: \" + str(testData.count()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIpDQAScIPSY"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\n",
        "\n",
        "lrModel = lr.fit(trainingData)\n",
        "\n",
        "predictions = lrModel.transform(testData)\n",
        "\n",
        "predictions.filter(predictions['prediction'] == 0) \\\n",
        "    .select(\"description\",\"category\",\"probability\",\"label\",\"prediction\") \\\n",
        "    .orderBy(\"probability\", ascending=False) \\\n",
        "    .show(n = 10, truncate = 30)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NiPwWRmIPSa"
      },
      "outputs": [],
      "source": [
        "df = predictions.select('description','category','label','prediction').toPandas()\n",
        "#df['result'] = df['result'].apply(lambda x: x[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4Q1XnpZIPSc"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEg_wD3oIPSe"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(classification_report(df.label, df.prediction))\n",
        "print(accuracy_score(df.label, df.prediction))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdODPjyzIPSf"
      },
      "source": [
        "### train on entire dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJu8ekkaIPSg"
      },
      "outputs": [],
      "source": [
        "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\n",
        "\n",
        "lrModel = lr.fit(use_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yo8sNiL4IPSh"
      },
      "outputs": [],
      "source": [
        "\n",
        "test_df = spark.read.parquet(\"data/news_category_test.parquet\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22hPNZ9jIPSi"
      },
      "outputs": [],
      "source": [
        "test_df = use_pipeline.fit(test_df).transform(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSJt_s4qIPSj"
      },
      "outputs": [],
      "source": [
        "test_df= test_df.withColumn(\"features\", explode(test_df.finished_use_embeddings))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g67zaIZWIPSl"
      },
      "outputs": [],
      "source": [
        "test_df.show(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cG0FjtySIPSm"
      },
      "outputs": [],
      "source": [
        "predictions = lrModel.transform(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnnF27fuIPSn"
      },
      "outputs": [],
      "source": [
        "df = predictions.select('description','category','label','prediction').toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daLNQqgAIPSp"
      },
      "outputs": [],
      "source": [
        "df['label'] = df.category.replace({'World':2.0,\n",
        "                    'Sports':3.0,\n",
        "                    'Business':0.0,\n",
        "                    'Sci/Tech':1.0})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4AORiLrIPSq"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZR2Hx1JIPSt"
      },
      "outputs": [],
      "source": [
        "print(classification_report(df.label, df.prediction))\n",
        "print(accuracy_score(df.label, df.prediction))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IY19YW8pIPSu"
      },
      "source": [
        "## Spark NLP Licensed DocClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66YJQISEIPSv"
      },
      "outputs": [],
      "source": [
        "from sparknlp_jsl.annotator import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AncnnRvWIPSw"
      },
      "outputs": [],
      "source": [
        "# set seed for reproducibility\n",
        "(trainingData, testData) = newsDF.randomSplit([0.7, 0.3], seed = 100)\n",
        "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
        "print(\"Test Dataset Count: \" + str(testData.count()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEmAIit1IPSy"
      },
      "outputs": [],
      "source": [
        "\n",
        "document_assembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"description\") \\\n",
        "    .setOutputCol(\"document\")\n",
        "    \n",
        "tokenizer = Tokenizer() \\\n",
        "  .setInputCols([\"document\"]) \\\n",
        "  .setOutputCol(\"token\")\n",
        "    \n",
        "normalizer = Normalizer() \\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"normalized\")\n",
        "\n",
        "stopwords_cleaner = StopWordsCleaner()\\\n",
        "      .setInputCols(\"normalized\")\\\n",
        "      .setOutputCol(\"cleanTokens\")\\\n",
        "      .setCaseSensitive(False)\n",
        "\n",
        "stemmer = Stemmer() \\\n",
        "    .setInputCols([\"cleanTokens\"]) \\\n",
        "    .setOutputCol(\"stem\")\n",
        "\n",
        "logreg = DocumentLogRegClassifierApproach()\\\n",
        "      .setInputCols([\"stem\"])\\\n",
        "      .setLabelCol(\"category\")\\\n",
        "      .setOutputCol(\"prediction\")\n",
        "\n",
        "nlp_pipeline = Pipeline(\n",
        "    stages=[document_assembler, \n",
        "            tokenizer,\n",
        "            normalizer,\n",
        "            stopwords_cleaner, \n",
        "            stemmer, \n",
        "           logreg])\n",
        "\n",
        "nlp_model = nlp_pipeline.fit(trainingData)\n",
        "\n",
        "processed = nlp_model.transform(testData)\n",
        "\n",
        "processed.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fHB9meKIPS0"
      },
      "outputs": [],
      "source": [
        "processed.select('description','category','prediction.result').show(truncate=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iX5PnC-SIPS1"
      },
      "outputs": [],
      "source": [
        "processed.select('description','prediction.result').show(truncate=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqyiWbFzIPS2"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWVkVKcfIPS4"
      },
      "outputs": [],
      "source": [
        "df = processed.select('description','category','prediction.result').toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jLQjD5uIPS5"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6PY-TpDKIPS6"
      },
      "outputs": [],
      "source": [
        "df.result[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N48rE1hAIPS8"
      },
      "outputs": [],
      "source": [
        "df = processed.select('description','category','prediction.result').toPandas()\n",
        "df['result'] = df['result'].apply(lambda x: x[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpPlewPVIPS9"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EbFttFExIPTA"
      },
      "outputs": [],
      "source": [
        "\n",
        "df = processed.select('description','category','prediction.result').toPandas()\n",
        "df['result'] = df['result'].apply(lambda x: x[0])\n",
        "\n",
        "print(classification_report(df.category, df.result))\n",
        "print(accuracy_score(df.category, df.result))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "regAngWEIPTB"
      },
      "source": [
        "# ClassifierDL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RfV7lB_IPTB"
      },
      "outputs": [],
      "source": [
        "# actual content is inside description column\n",
        "document = DocumentAssembler()\\\n",
        "    .setInputCol(\"description\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "use = UniversalSentenceEncoder.load('/Users/vkocaman/cache_pretrained/tfhub_use_en_2.4.4_2.4_1583158595769')\\\n",
        " .setInputCols([\"document\"])\\\n",
        " .setOutputCol(\"sentence_embeddings\")\n",
        "\n",
        "# the classes/labels/categories are in category column\n",
        "classsifierdl = ClassifierDLApproach()\\\n",
        "  .setInputCols([\"sentence_embeddings\"])\\\n",
        "  .setOutputCol(\"class\")\\\n",
        "  .setLabelColumn(\"category\")\\\n",
        "  .setMaxEpochs(5)\\\n",
        "  .setEnableOutputLogs(True)\n",
        "\n",
        "pipeline = Pipeline(\n",
        "    stages = [\n",
        "        document,\n",
        "        use,\n",
        "        classsifierdl\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4A_zgocgIPTD"
      },
      "outputs": [],
      "source": [
        "# set seed for reproducibility\n",
        "(trainingData, testData) = newsDF.randomSplit([0.7, 0.3], seed = 100)\n",
        "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
        "print(\"Test Dataset Count: \" + str(testData.count()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H47jOwwCIPTG"
      },
      "outputs": [],
      "source": [
        "pipelineModel = pipeline.fit(trainingData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGI1c50EIPTH"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "df = pipelineModel.transform(testDataset).select('category','description',\"class.result\").toPandas()\n",
        "\n",
        "df['result'] = df['result'].apply(lambda x: x[0])\n",
        "\n",
        "print(classification_report(df.category, df.result))\n",
        "print(accuracy_score(df.category, df.result))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkeFxX8tIPTJ"
      },
      "source": [
        "## Loading the trained classifier from disk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VOg7XsKIPTJ"
      },
      "outputs": [],
      "source": [
        "classsifierdlmodel = ClassifierDLModel.load('classifierDL_model_20200317_5e')\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACf2NVAkIPTK"
      },
      "outputs": [],
      "source": [
        "import sparknlp\n",
        "sparknlp.__path__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q81gbD7tIPTL"
      },
      "outputs": [],
      "source": [
        " .setInputCols([\"sentence_embeddings\"])\\\n",
        "  .setOutputCol(\"class\")\\\n",
        "  .setLabelColumn(\"category\")\\\n",
        "  .setMaxEpochs(5)\\\n",
        "  .setEnableOutputLogs(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vS0TSHm9IPTM"
      },
      "outputs": [],
      "source": [
        "trainDataset = spark.read \\\n",
        "      .option(\"header\", True) \\\n",
        "      .csv(\"data/news_category_train.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_mc12vtIPTO"
      },
      "outputs": [],
      "source": [
        "trainDataset.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGFoCY9WIPTP"
      },
      "outputs": [],
      "source": [
        "trainingData.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkStUCiJIPTR"
      },
      "outputs": [],
      "source": [
        "document = DocumentAssembler()\\\n",
        "    .setInputCol(\"description\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "\n",
        "sentence = SentenceDetector()\\\n",
        "    .setInputCols(['document'])\\\n",
        "    .setOutputCol('sentence')\n",
        "\n",
        "use = UniversalSentenceEncoder.load('/Users/vkocaman/cache_pretrained/tfhub_use_en_2.4.4_2.4_1583158595769')\\\n",
        " .setInputCols([\"sentence\"])\\\n",
        " .setOutputCol(\"sentence_embeddings\")\n",
        "\n",
        "classsifierdlmodel = ClassifierDLModel.load('classifierDL_model_20200317_5e')\n",
        "\n",
        "pipeline = Pipeline(\n",
        "    stages = [\n",
        "        document,\n",
        "        sentence,\n",
        "        use,\n",
        "        classsifierdlmodel\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRk7zctqIPTS"
      },
      "outputs": [],
      "source": [
        "pipeline.fit(testData.limit(1)).transform(testData.limit(10)).select('category','description',\"class.result\").show(10, truncate=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04z0AN66IPTT"
      },
      "outputs": [],
      "source": [
        "lm = LightPipeline(pipeline.fit(testDataset.limit(1)))\n",
        "lm.annotate('In its first two years, the UK dedicated card companies have surge')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzdks_VjIPTV"
      },
      "outputs": [],
      "source": [
        "text='''\n",
        "Fearing the fate of Italy, the centre-right government has threatened to be merciless with those who flout tough restrictions. As of Wednesday it will also include all shops being closed across Greece, with the exception of supermarkets. Banks, pharmacies, pet-stores, mobile phone stores, opticians, bakers, mini-markets, couriers and food delivery outlets are among the few that will also be allowed to remain open.\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eltINENfIPTW"
      },
      "outputs": [],
      "source": [
        "lm = LightPipeline(pipeline.fit(testDataset.limit(1)))\n",
        "\n",
        "lm.annotate(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXXfKtIrIPTY"
      },
      "source": [
        "# Classifier DL + Glove + Basic text processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAPb8TqgIPTY"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "boEt-9goIPTZ"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer() \\\n",
        "  .setInputCols([\"document\"]) \\\n",
        "  .setOutputCol(\"token\")\n",
        "\n",
        "lemma = LemmatizerModel.pretrained('lemma_antbnc') \\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"lemma\")\n",
        "\n",
        "lemma_pipeline = Pipeline(\n",
        "    stages=[document_assembler, \n",
        "            tokenizer,\n",
        "            lemma,\n",
        "           glove_embeddings])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_yAmuyKPIPTc"
      },
      "outputs": [],
      "source": [
        "lemma_pipeline.fit(trainingData.limit(1000)).transform(trainingData.limit(1000)).show(truncate=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y22Ln3U1IPTe"
      },
      "outputs": [],
      "source": [
        "document_assembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"description\") \\\n",
        "    .setOutputCol(\"document\")\n",
        "    \n",
        "tokenizer = Tokenizer() \\\n",
        "  .setInputCols([\"document\"]) \\\n",
        "  .setOutputCol(\"token\")\n",
        "    \n",
        "normalizer = Normalizer() \\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"normalized\")\n",
        "\n",
        "stopwords_cleaner = StopWordsCleaner()\\\n",
        "      .setInputCols(\"normalized\")\\\n",
        "      .setOutputCol(\"cleanTokens\")\\\n",
        "      .setCaseSensitive(False)\n",
        "\n",
        "lemma = LemmatizerModel.pretrained('lemma_antbnc') \\\n",
        "    .setInputCols([\"cleanTokens\"]) \\\n",
        "    .setOutputCol(\"lemma\")\n",
        "\n",
        "glove_embeddings = WordEmbeddingsModel().pretrained() \\\n",
        " .setInputCols([\"document\",'lemma'])\\\n",
        " .setOutputCol(\"embeddings\")\\\n",
        " .setCaseSensitive(False)\n",
        "\n",
        "embeddingsSentence = SentenceEmbeddings() \\\n",
        "      .setInputCols([\"document\", \"embeddings\"]) \\\n",
        "      .setOutputCol(\"sentence_embeddings\") \\\n",
        "      .setPoolingStrategy(\"AVERAGE\")\n",
        "\n",
        "classsifierdl = ClassifierDLApproach()\\\n",
        "  .setInputCols([\"sentence_embeddings\"])\\\n",
        "  .setOutputCol(\"class\")\\\n",
        "  .setLabelColumn(\"category\")\\\n",
        "  .setMaxEpochs(10)\\\n",
        "  .setEnableOutputLogs(True)\n",
        "\n",
        "clf_pipeline = Pipeline(\n",
        "    stages=[document_assembler, \n",
        "            tokenizer,\n",
        "            normalizer,\n",
        "            stopwords_cleaner, \n",
        "            lemma, \n",
        "            glove_embeddings,\n",
        "            embeddingsSentence,\n",
        "            classsifierdl])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nkk_c53gIPTf"
      },
      "outputs": [],
      "source": [
        "!rm -rf classifier_dl_pipeline_glove"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81fkjlNaIPTh"
      },
      "outputs": [],
      "source": [
        "clf_pipelineModel.save('classifier_dl_pipeline_glove')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJdGzsWcIPTk"
      },
      "outputs": [],
      "source": [
        "clf_pipelineModel = clf_pipeline.fit(trainingData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HX7wxbU0IPTl"
      },
      "outputs": [],
      "source": [
        "df = clf_pipelineModel.transform(testDataset).select('category','description',\"class.result\").toPandas()\n",
        "\n",
        "df['result'] = df['result'].apply(lambda x: x[0])\n",
        "\n",
        "print(classification_report(df.category, df.result))\n",
        "\n",
        "print(accuracy_score(df.category, df.result))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81Yor2ybIPTm"
      },
      "outputs": [],
      "source": [
        "!cd data && ls -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4I6cK4BIPTn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CaINbN4RIPTp"
      },
      "outputs": [],
      "source": [
        "news_df = newsDF.toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULAoM_6rIPTr"
      },
      "outputs": [],
      "source": [
        "news_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hp6nDSBCIPTu"
      },
      "outputs": [],
      "source": [
        "news_df.to_csv('data/news_dataset.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "733xg3xwIPTv"
      },
      "outputs": [],
      "source": [
        "document_assembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"description\") \\\n",
        "    .setOutputCol(\"document\")\n",
        "    \n",
        "tokenizer = Tokenizer() \\\n",
        "  .setInputCols([\"document\"]) \\\n",
        "  .setOutputCol(\"token\")\n",
        "    \n",
        "normalizer = Normalizer() \\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"normalized\")\n",
        "\n",
        "stopwords_cleaner = StopWordsCleaner()\\\n",
        "      .setInputCols(\"normalized\")\\\n",
        "      .setOutputCol(\"cleanTokens\")\\\n",
        "      .setCaseSensitive(False)\n",
        "\n",
        "lemma = LemmatizerModel.pretrained('lemma_antbnc') \\\n",
        "    .setInputCols([\"cleanTokens\"]) \\\n",
        "    .setOutputCol(\"lemma\")\n",
        "\n",
        "glove_embeddings = WordEmbeddingsModel().pretrained() \\\n",
        " .setInputCols([\"document\",'lemma'])\\\n",
        " .setOutputCol(\"embeddings\")\\\n",
        " .setCaseSensitive(False)\n",
        "\n",
        "txt_pipeline = Pipeline(\n",
        "    stages=[document_assembler, \n",
        "            tokenizer,\n",
        "            normalizer,\n",
        "            stopwords_cleaner, \n",
        "            lemma, \n",
        "            glove_embeddings,\n",
        "            embeddingsSentence])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJHq4FdNIPTx"
      },
      "outputs": [],
      "source": [
        "\n",
        "txt_pipelineModel = txt_pipeline.fit(testData.limit(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mixFG3jjIPTy"
      },
      "outputs": [],
      "source": [
        "txt_pipelineModel.save('text_prep_pipeline_glove')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJQiXr4BIPTz"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHsc2ClYIPUJ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "spark_05_Text_classification_examples_in_SparkML_SparkNLP.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}